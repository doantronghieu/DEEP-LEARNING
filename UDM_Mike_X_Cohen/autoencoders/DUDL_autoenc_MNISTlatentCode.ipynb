{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"YeuAheYyhdZw"},"outputs":[],"source":["# For DL modeling\n","import torch\n","from torch.utils.data import TensorDataset, DataLoader\n","import torch.nn.functional as F\n","import torch.nn as nn\n","\n","# For number-crunching\n","import numpy as np\n","import scipy.stats as stats\n","\n","# For dataset management\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","# For data visualization\n","import matplotlib.pyplot as plt\n","from IPython import display\n","display.set_matplotlib_formats('svg')\n","import seaborn as sns\n","\n","# For timing computations\n","import time\n","\n","import copy\n","\n","import sklearn.metrics as skm\n","\n","import sys\n","\n","# For doing PCA on the model output\n","from sklearn.decomposition import PCA"]},{"cell_type":"markdown","metadata":{"id":"0HOkOefftqyg"},"source":["# Import and process the data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MU7rvmWuhjud"},"outputs":[],"source":["# Import dataset\n","mnist_dataset = np.loadtxt(open('sample_data/mnist_train_small.csv','rb'), delimiter=',')\n","\n","#Extract labels (number IDs) and remove from data\n","labels = mnist_dataset[:, 0]\n","data   = mnist_dataset[:, 1:]\n","\n","# Normalize the data to a range of [0, 1]\n","data_norm = data / np.max(data)\n","\n","# Convert to tensor\n","data_tensor   = torch.tensor(data_norm).float()"]},{"cell_type":"markdown","metadata":{"id":"OK8Opkhgp0bO"},"source":["# Create the DL model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JK3OO3tAtZkA"},"outputs":[],"source":["# Create a class for the model\n","def create_the_MNIST_AE():\n","    \"\"\"\n","    AUTOENCODER_ LATENT_CODE\n","    \"\"\"\n","    class ae_net(nn.Module):\n","        def __init__(self):\n","            super().__init__()\n","\n","            # Input layer\n","            self.input = nn.Linear(784, 150)\n","\n","            # Encoder layer\n","            self.enc = nn.Linear(150, 15)\n","\n","            # Latent layer\n","            self.lat = nn.Linear(15, 150)\n","\n","            # Decoder layer\n","            self.dec = nn.Linear(150, 784)\n","    \n","        # Forward pass\n","        def forward(self, x):\n","            x     = F.relu(self.input(x))\n","            codex = F.relu(self.enc(x)) # Output the hidden-layer activation\n","            x     = F.relu(self.lat(codex))\n","            y     = torch.sigmoid(self.dec(x))\n","\n","            return y, codex\n","    \n","    # Create the model instance\n","    net = ae_net()\n","\n","    # Loss function\n","    loss_func = nn.MSELoss()\n","\n","    # Optimizer\n","    optimizer = torch.optim.Adam(params=net.parameters(), lr=0.001)\n","\n","    return net, loss_func, optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"voQ6mHkfmj1F"},"outputs":[],"source":["# Test the model with a bit of data\n","net, loss_func, optimizer = create_the_MNIST_AE()\n","\n","X     = data_tensor[:5, :]\n","y_hat = net(X)\n","\n","print(f'Input shape: {X.shape}', '\\n')\n","print(type(y_hat), len(y_hat), '\\n')\n","print(f'Shape of model output: {y_hat[0].shape}', '\\n')\n","print(f'Shape of encoding layer output: {y_hat[1].shape}', '\\n')"]},{"cell_type":"markdown","metadata":{"id":"dvfGQIRGp0ht"},"source":["# Create a function that trains the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IblJo1NCp0kl"},"outputs":[],"source":["def train_the_model():\n","    \"\"\"\n","    AUTOENCODER_DENOISING_MNIST|LATENT_CODE\n","    \"\"\"\n","\n","    num_epochs = 10000\n","\n","    # Create a new model\n","    net, loss_func, optimizer = create_the_MNIST_AE()\n","\n","    # Initialize losses\n","    losses = torch.zeros(num_epochs)\n","\n","    # Loop over epochs\n","    for epoch_i in range(num_epochs):\n","\n","        # Select a random set of images\n","        random_idx = np.random.choice(data_tensor.shape[0], size=32)\n","        X          = data_tensor[random_idx, :]\n","\n","        # Forward pass and loss\n","        y_hat = net(X)\n","        loss  = loss_func(y_hat, X)\n","\n","        # Backprop\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Losses in this epoch\n","        losses[epoch_i] = loss.item()\n","    \n","    # End epochs\n","    # Function output\n","    return losses, net"]},{"cell_type":"markdown","metadata":{"id":"XpGm9xdQ27Ob"},"source":["# Run the model and show the results!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l9pCC1R2p0nu"},"outputs":[],"source":["# Train the model\n","losses, net = train_the_model()\n","print(f'Final loss: {losses[-1]:.4f}')\n","\n","# Visualize the losses\n","plt.plot(losses, '.-')\n","plt.xlabel('Epochs')\n","plt.ylabel('Model loss')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"pG7_3tYbp0wm"},"source":["# Inspect the latent \"code\" of the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qw56zhmj87WC"},"outputs":[],"source":["# Output the latent layer\n","# Push through the entire dataset\n","y_hat, latent = net(data_tensor)\n","\n","# Print sizes\n","print(f'{y_hat.shape}, {latent.shape}')\n","\n","fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n","\n","ax[0].hist(latent.flatten().detach(), 100)\n","ax[0].set_xlabel('Latent Activation value')\n","ax[0].set_ylabel('Count')\n","ax[0].set_title('Distribution of latent units activation')\n","\n","ax[1].imshow(latent.detach(), aspect='auto', vmin=0, vmax=10)\n","ax[1].set_xlabel('Latent node')\n","ax[1].set_ylabel('Image number')\n","ax[1].set_title('All latent activations')\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9SnUUHPm7xQE"},"outputs":[],"source":["# compute the average latent activation for each digit type\n","\n","# initialize output matrix (latent shape by 10 digits)\n","sourcecode = np.zeros((latent.shape[1],10))\n","\n","\n","# loop over digit categories\n","for i in range(10):\n","\n","  # find all pictures of this category\n","  digidx = np.where(labels==i)\n","\n","  # average the latent layer output\n","  sourcecode[:,i] = torch.mean(latent[digidx,:],axis=1).detach()\n","\n","\n","# let's see what it looks like!\n","fig = plt.figure(figsize=(8,5))\n","\n","plt.plot(sourcecode,'s-')\n","plt.legend(range(10),loc=(1.01,.4))\n","plt.xticks(range(15))\n","plt.xlabel('Latent node number')\n","plt.ylabel('Activation')\n","plt.title(\"The model's internal representation of the numbers\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"RumWkrM82B8N"},"source":["# Explore the reduced-compressed space with PCA"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mRrEQMXgrCQj"},"outputs":[],"source":["# compute and fit the PCA\n","pcaData = PCA(n_components=15).fit(data) # 15 components to match latent, but it's just to speed computation time\n","pcaCode = PCA(               ).fit(latent.detach())\n","\n","\n","# plot the eigenspectra (scree plot)\n","plt.plot(100*pcaData.explained_variance_ratio_,'s-',label='Data PCA')\n","plt.plot(100*pcaCode.explained_variance_ratio_,'o-',label='Code PCA')\n","plt.xlabel('Components')\n","plt.ylabel('Percent variance explained')\n","plt.title('PCA scree plot')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9cAVDrS5vbWC"},"outputs":[],"source":["# compute the projection of the data onto the PC axes\n","scoresData = pcaData.fit_transform(data)\n","scoresCode = pcaCode.fit_transform(latent.detach())\n","\n","# plot the data separately per number\n","fig,ax = plt.subplots(1,2,figsize=(15,5))\n","\n","for lab in range(10):\n","  ax[0].plot(scoresData[labels==lab,0],scoresData[labels==lab,1],'o',markersize=3,alpha=.4)\n","  ax[1].plot(scoresCode[labels==lab,0],scoresCode[labels==lab,1],'o',markersize=3,alpha=.4)\n","\n","for i in range(2):\n","  ax[i].set_xlabel('PC1 projection')\n","  ax[i].set_ylabel('PC2 projection')\n","  ax[i].legend(range(10))\n","\n","ax[0].set_title('PCA of data')\n","ax[1].set_title('PCA of latent code')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3vB1b_MGBlVv"},"outputs":[],"source":["# This cell is not important! It's just the code I used to make the figure in the slide. I decided to leave it here FYI.\n","\n","fig,ax = plt.subplots(1,3,figsize=(15,3))\n","\n","ax[0].imshow(dataT[0,:].view(28,28),cmap='gray')\n","\n","ax[1].plot(dataT[0,:],'ks')\n","ax[1].set_xlabel('Pixels (vectorized)')\n","ax[1].set_ylabel('Intensity value')\n","\n","ax[2].plot(latent[0,:].detach(),'ks')\n","ax[2].set_xlabel('Latent units')\n","ax[2].set_ylabel('Activation (a.u.)')\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nlmKG35AVGJp"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"Uh28k_l29urR"},"source":["# Additional explorations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ib3uQtfv9wE2"},"outputs":[],"source":["# 1) Are you surprised that the latent activations (e.g., from the histogram) are all non-negative? Is that because of \n","#    the image normalization, or what is causing those values to be all non-negative?\n","# \n","# 2) Averages don't tell the whole story. Redraw the \"Model's internal representation\" line plot but using standard \n","#    deviation instead of mean. This graph will tell you if any numbers, or units, have particularly higher variability\n","#    than others. Is this the case, and does the std plot give you any more insight into the model's learned representation?\n","# \n","# 3) The PC-space plots are tricky to interpret: This is a 15-dimensional space but 13 dimensions are projected onto two.\n","#    It's possible that the numbers are better separated in other dimensions, just like a 2D photograph of someone standing\n","#    behind a tree makes them inseparable whereas they are separable in the original 3D space. Modify the plot to show\n","#    PC dimensions 2&3 instead of 1&2. \n","# "]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO+XbpZzuIwe31qEBui38Be","collapsed_sections":[],"name":"DUDL_autoenc_MNISTlatentCode.ipynb","provenance":[{"file_id":"19G9gTeBlYPQ-s3VS_3K2bVFtKTP344j6","timestamp":1619266919349},{"file_id":"1FcEBC0NAESIlHQkv6_85R-XDUKGE8XbM","timestamp":1619155961717},{"file_id":"1qKgZ8kVcqNgwtBzHbWq5yJH_HqI6DxWW","timestamp":1617803880910},{"file_id":"15cpyHkJ435B4MqbyGjAH1poN4nCy_DE4","timestamp":1617737766196},{"file_id":"1OLuWuaFu0hcFgkQ2hh5BqbRuqUZD7XcQ","timestamp":1617734878578},{"file_id":"1XvzVGJPTJifVh8OpZVB7ykLxyUqYwQ1j","timestamp":1617196833019},{"file_id":"1bv1_y32e3KEExFKKlPfC3rpw1JxmBr8H","timestamp":1617124341706},{"file_id":"1GMq8u7KyHB2AE7Teyls9gK1T01OduQSn","timestamp":1616697516760},{"file_id":"1Ui3kyHim-e0XLgDs2mkBxVlYg7TKYtcg","timestamp":1616615469755},{"file_id":"1YpHocGI4rApOxIBb1ZghCU5L-hFnv4CK","timestamp":1616608248670}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
