{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"YeuAheYyhdZw"},"outputs":[],"source":["# import libraries\n","import numpy as np\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"markdown","metadata":{},"source":["# Fake dataset"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"q-YUb7pW19yy"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[ 11  12  13  14]\n"," [ 21  22  23  24]\n"," [ 31  32  33  34]\n"," [ 41  42  43  44]\n"," [ 51  52  53  54]\n"," [ 61  62  63  64]\n"," [ 71  72  73  74]\n"," [ 81  82  83  84]\n"," [ 91  92  93  94]\n"," [101 102 103 104]]\n"," \n","[False False False False False  True  True  True  True  True]\n"]}],"source":["fakedata = np.tile(np.array([1,2,3,4]),(10,1)) + np.tile(10*np.arange(1,11),(4,1)).T\n","fakelabels = np.arange(10)>4\n","print(fakedata), print(' ')\n","print(fakelabels)"]},{"cell_type":"markdown","metadata":{"id":"UhkvsJ6g6uXr"},"source":["# Using train_test_split"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"8bxbHGkP7JW3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training set size: (8, 4)\n","Dev set size: (1, 4)\n","Test set size: (1, 4)\n","-------------------------------------------\n","[[ 41  42  43  44]\n"," [ 71  72  73  74]\n"," [ 21  22  23  24]\n"," [ 11  12  13  14]\n"," [ 51  52  53  54]\n"," [ 61  62  63  64]\n"," [ 31  32  33  34]\n"," [101 102 103 104]] \n","\n","[[91 92 93 94]] \n","\n","[[81 82 83 84]] \n","\n"]}],"source":["# Specify sizes of the partitions\n","# Order is train, devset, test\n","partitions = [0.8, 0.1, 0.1]\n","\n","# Split the data (note the third input, and the TMP in the variable name)\n","train_data, temp_data, train_labels, temp_label \\\n","    = train_test_split(fakedata, fakelabels, train_size=partitions[0])\n","\n","# Now split the TMP data\n","split = partitions[1] / np.sum(partitions[1:])\n","dev_data, test_data, dev_labels, test_labels \\\n","    = train_test_split(temp_data, temp_label, train_size=split)\n","\n","# Print out the sizes\n","print(f'Training set size: {train_data.shape}')\n","print(f'Dev set size: {dev_data.shape}')\n","print(f'Test set size: {test_data.shape}')\n","print('-------------------------------------------')\n","# Print out the train/test data\n","print(train_data, '\\n')\n","print(dev_data, '\\n')\n","print(test_data, '\\n')"]},{"cell_type":"markdown","metadata":{"id":"EvUQFxSTV2SB"},"source":["# Splitting the data manually using numpy"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"XUZcKNWsXg00"},"outputs":[{"name":"stdout","output_type":"stream","text":["Partition boundaries: [ 8  9 10]\n","Randomized data indices: [8 3 1 5 6 9 2 0 4 7]\n"]}],"source":["# Partition sizes in proportion\n","partitions = np.array([0.8, 0.1, 0.1])\n","\n","# Convert those into integers\n","partition_bound = np.cumsum(partitions * len(fakelabels)).astype(int)\n","print(f'Partition boundaries: {partition_bound}')\n","\n","# Random indices\n","rand_indices = np.random.permutation(range(len(fakelabels)))\n","print(f'Randomized data indices: {rand_indices}')"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"Vre4YiQBZmjy"},"outputs":[],"source":["# Select rows for the training data\n","train_dataN = fakedata[rand_indices[:partition_bound[0]], :]\n","train_labelsN = fakelabels[rand_indices[:partition_bound[0]]]\n","\n","# Select rows for the devset data\n","dev_dataN = fakedata[rand_indices[partition_bound[0]:partition_bound[1]], :]\n","dev_labelsN = fakelabels[rand_indices[partition_bound[0]:partition_bound[1]]]\n","\n","# Select rows for the test data\n","test_dataN = fakedata[rand_indices[partition_bound[1]:partition_bound[2]], :]\n","test_labelsN = fakelabels[rand_indices[partition_bound[1]:partition_bound[2]]]"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"vbTLW0MkXg-V"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training set size: (8, 4)\n","Dev set size: (1, 4)\n","Test set size: (1, 4)\n","-------------------------------------------\n","[[ 91  92  93  94]\n"," [ 41  42  43  44]\n"," [ 21  22  23  24]\n"," [ 61  62  63  64]\n"," [ 71  72  73  74]\n"," [101 102 103 104]\n"," [ 31  32  33  34]\n"," [ 11  12  13  14]] \n","\n","[[51 52 53 54]] \n","\n","[[81 82 83 84]] \n","\n"]}],"source":["# Print out the sizes\n","print(f'Training set size: {train_dataN.shape}')\n","print(f'Dev set size: {dev_dataN.shape}')\n","print(f'Test set size: {test_dataN.shape}')\n","print('-------------------------------------------')\n","# Print out the train/test data\n","print(train_dataN, '\\n')\n","print(dev_dataN, '\\n')\n","print(test_dataN, '\\n')"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyORIyTWClz7YOKdhmp8/3fQ","collapsed_sections":[],"name":"DUDL_overfitting_trainDevsetTest.ipynb","provenance":[{"file_id":"1Ui3kyHim-e0XLgDs2mkBxVlYg7TKYtcg","timestamp":1616615469755},{"file_id":"1YpHocGI4rApOxIBb1ZghCU5L-hFnv4CK","timestamp":1616608248670}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}
