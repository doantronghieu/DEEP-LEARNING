{"cells":[{"cell_type":"code","execution_count":31,"metadata":{"id":"YeuAheYyhdZw"},"outputs":[],"source":["# import libraries\n","import torch\n","import torch.nn as nn\n","import numpy as np"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"MU7rvmWuhjud"},"outputs":[{"data":{"text/plain":["tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n","        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n","        2, 2, 2, 2, 2, 2])"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["# Import dataset (comes with seaborn)\n","import seaborn as sns\n","iris = sns.load_dataset('iris')\n","\n","# Convert from pandas dataframe to tensor | Final column is the outcome variable\n","data = torch.tensor(iris[iris.columns[0:4]].values).float()\n","\n","# Transform species to number\n","labels = torch.zeros(len(data), dtype=torch.long)\n","\n","# Labels[iris.species=='setosa'] = 0 # don't need!\n","labels[iris.species == 'versicolor'] = 1\n","labels[iris.species == 'virginica'] = 2\n","\n","labels # The data is not randomized!"]},{"cell_type":"markdown","metadata":{"id":"JiAFAHB20DQc"},"source":["# Separate data into train and test"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"mwhgV43SXbCN"},"outputs":[{"name":"stdout","output_type":"stream","text":["[ True  True  True  True  True  True  True  True  True  True  True  True\n","  True  True  True  True  True  True  True  True  True  True  True  True\n","  True  True  True  True  True  True  True  True  True  True  True  True\n","  True  True  True  True  True  True  True  True  True  True  True  True\n","  True  True  True  True  True  True  True  True  True  True  True  True\n","  True  True  True  True  True  True  True  True  True  True  True  True\n","  True  True  True  True  True  True  True  True  True  True  True  True\n","  True  True  True  True  True  True  True  True  True  True  True  True\n","  True  True  True  True  True  True  True  True  True  True  True  True\n","  True  True  True  True  True  True  True  True  True  True  True  True\n"," False False False False False False False False False False False False\n"," False False False False False False False False False False False False\n"," False False False False False False] \n","\n","[ True  True  True  True  True  True  True  True  True  True  True  True\n","  True False  True  True False False False  True  True  True False  True\n","  True  True  True  True  True  True False  True  True  True  True  True\n","  True False  True False  True  True  True  True  True  True  True  True\n","  True False  True  True  True  True  True False  True  True False False\n","  True  True  True  True  True  True  True False  True  True  True False\n","  True  True  True  True  True  True False False False  True  True  True\n","  True  True  True  True False False  True  True False  True False  True\n"," False  True  True  True  True  True  True  True  True  True  True  True\n"," False  True  True  True  True  True  True False False  True  True  True\n","  True  True  True  True  True  True  True  True  True  True  True  True\n","  True  True  True  True  True False  True False  True  True False  True\n","  True  True  True False False  True]\n"]}],"source":["#  (no devset here)\n","\n","# How many training examples\n","prop_training = .8 # In proportion, not percent\n","n_training = int(len(labels) * prop_training)\n","\n","# Initialize a boolean vector to select data and labels | Each value = 1 row (sample) in dataset | True: Go to training set, False: Go to test set\n","train_test_bool = np.zeros(shape=len(labels), dtype=bool)\n","train_test_bool0 = np.zeros(shape=len(labels), dtype=bool)\n","\n","# Is this the correct way to select samples?\n","train_test_bool0[range(n_training)] = True\n","print(train_test_bool0, '\\n')\n","\n","item_2_use_4_train = np.random.choice(range(len(labels)), n_training, replace=False)\n","train_test_bool[item_2_use_4_train] = True\n","# This is better, but why?\n","print(train_test_bool)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Test whether it's balanced"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"LPcj_f92bYs0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Average of full data: 1.0\n","\n","Average of training data: 1.0083333253860474\n","\n","Average of test data: 0.9666666388511658\n"]}],"source":["print(f'Average of full data: {torch.mean(labels.float())}') # = 1 by definition\n","print('')\n","\n","print(f'Average of training data: {torch.mean(labels[train_test_bool].float())}') # Should be 1\n","print('')\n","\n","print(f'Average of test data: {torch.mean(labels[~train_test_bool].float())}') # Should be 1"]},{"cell_type":"markdown","metadata":{"id":"ZwusZlcu2VVS"},"source":["# Create the ANN model"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"v0JMIGb1iV_9"},"outputs":[],"source":["# Model architecture\n","ANN_iris = nn.Sequential(\n","  nn.Linear(in_features=4, out_features=64),  # Input layer\n","  nn.ReLU(),                                  # Activation\n","  nn.Linear(in_features=64, out_features=64), # Hidden layer\n","  nn.ReLU(),                                  # Activation\n","  nn.Linear(in_features=64, out_features=3),  # Output layer\n",")\n","\n","# Loss function | Include Softmax function \n","loss_func = nn.CrossEntropyLoss()\n","\n","# Optimizer\n","optimizer = torch.optim.SGD(params=ANN_iris.parameters(), lr=0.01)"]},{"cell_type":"markdown","metadata":{},"source":["# Evaluate Train/Test set"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"iyxr6_P9b-x5"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([150, 4])\n","torch.Size([120, 4])\n","torch.Size([30, 4])\n"]}],"source":["# Entire dataset\n","print(data.shape)\n","\n","# Training set\n","train_set = data[train_test_bool, :]\n","print(train_set.shape)\n","\n","# Test set\n","test_set = data[~train_test_bool, :]\n","print(test_set.shape)"]},{"cell_type":"markdown","metadata":{"id":"bbx3Zkc_0UT8"},"source":["# Train and test the model"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"cVD1nFTli7TO"},"outputs":[],"source":["num_epochs = 1000\n","\n","# Initialize losses\n","losses = torch.zeros(num_epochs)\n","ongoing_acc = []\n","\n","# Loop over epochs\n","for epoch_i in range(num_epochs):\n","  # Forward pass\n","  y_hat = ANN_iris(train_set)\n","\n","  # Compute loss\n","  loss = loss_func(y_hat, labels[train_test_bool])\n","  losses[epoch_i] = loss\n","\n","  # Backprop\n","  optimizer.zero_grad()\n","  loss.backward()\n","  optimizer.step()\n","\n","  # Compute accuracy\n","  matches = torch.argmax(y_hat, axis=1) == labels[train_test_bool]   # Booleans (True/False)\n","  matches_numeric = matches.float()                                  # Convert to numbers (0/1)\n","  accuracy_pct = 100 * torch.mean(matches_numeric)                   # Average and *100\n","  ongoing_acc.append(accuracy_pct)                                   # Add to list of accuracies"]},{"cell_type":"markdown","metadata":{},"source":["# Compute train and test accuracies"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Final TRAIN accuracy: 97.5\n","Final TEST accuracy: 100.0\n"]}],"source":["# Final forward pass using TRAINING data\n","predictions = ANN_iris(train_set)\n","pred_labels = torch.argmax(predictions, axis=1)     # Vector of the index of the largest value in each row (sample)\n","train_acc = 100 * torch.mean((pred_labels == labels[train_test_bool]).float())\n","\n","# Final forward pass using TEST data\n","predictions = ANN_iris(test_set)\n","pred_labels = torch.argmax(predictions, axis=1)     # Vector of the index of the largest value in each row (sample)\n","test_acc = 100 * torch.mean((pred_labels == labels[~train_test_bool]).float())\n","\n","# Report accuracies\n","print(f'Final TRAIN accuracy: {train_acc}')\n","print(f'Final TEST accuracy: {test_acc}')"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"kcbD9nZmd9nu"},"outputs":[],"source":["# normally also inspect losses and accuracy by epoch, etc etc etc."]},{"cell_type":"markdown","metadata":{"id":"jwTbABK7fqzZ"},"source":["# Additional explorations\n","1) Randomly assigning data samples to be in the train vs test phase produced a statistical balance, but it was \n","   not perfect. Write an algorithm that will guarantee a balance of flower types while also randomly assigning\n","   samples to be in train vs. test.\n","\n","2) Revert the code to its original form -- with the strong imbalance in flower types. Then train the model. What are\n","   the train and test accuracies? Compute the accuracy separately for each type of flower to see whether the model\n","   learned some categories, or whether it performed equally on all three categories. Are you surprised at the results? "]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNk9aAiPToKpfieCvxrzbDR","collapsed_sections":[],"name":"DUDL_overfitting_manual.ipynb","provenance":[{"file_id":"1YpHocGI4rApOxIBb1ZghCU5L-hFnv4CK","timestamp":1616608248670}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}
