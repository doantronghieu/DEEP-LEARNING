{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"2TD8IyfBGXiY"},"outputs":[],"source":["# import libraries\n","import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"yo63BJPf0cau"},"source":["# Reminder of entropy:\n","\n","$$H(p) = -\\sum_x p(x)\\log(p(x))$$"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"vmjUxlEqGbDu"},"outputs":[{"name":"stdout","output_type":"stream","text":["Wrong entropy: 0.34657359027997264\n"]}],"source":["# Probability of an event happening\n","p = .25\n","\n","# NOT the correct formula!\n","H = -(p * np.log(p))\n","print('Wrong entropy: ' + str(H))\n"]},{"cell_type":"markdown","metadata":{},"source":["Remember to sum all the values of `x`"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"HdZadwd12RGv"},"outputs":[{"name":"stdout","output_type":"stream","text":["Correct entropy: 0.5623351446188083\n"]}],"source":["# Probability of an event not happening\n","q = 1 - p\n","\n","# The correct way to compute entropy\n","x = [p, q]\n","\n","# Initialize entropy to be zero\n","H = 0\n","\n","for p in x:\n","  H -= p * np.log(p)\n","\n","print('Correct entropy: ' + str(H))"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"R_bGT7kd2ipR"},"outputs":[{"name":"stdout","output_type":"stream","text":["Correct entropy: 0.5623351446188083\n"]}],"source":["# Also correct, written out for N=2 events\n","# Binary entropy (Entropy for 02 events)\n","H = -(p*np.log(p) + (1 - p)*np.log(1 - p))\n","print('Correct entropy: ' + str(H))"]},{"cell_type":"markdown","metadata":{"id":"qFN5779d1ebD"},"source":["# Cross-entropy"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"sOug_tPzHY1y"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cross entropy: 1.3862943611198906\n"]}],"source":["# Note: all probs must sum to 1!\n","p = [   1, .0   ]   # sum=1|The truth      |1: Is a cat, 0: Is not a cat\n","q = [ .25, .75  ]   # sum=1|The model say\n","\n","H = 0\n","for i in range(len(p)):\n","  H -= p[i] * np.log(q[i])\n","\n","print('Cross entropy: ' + str(H))"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"8H1p7JUr3Pn4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Correct entropy: 1.3862943611198906\n","Manually simplified: 1.3862943611198906\n"]}],"source":["# Also correct, written out for N=2 events\n","# Binary cross entropy\n","H = -(p[0]*np.log(q[0]) + p[1]*np.log(q[1]))\n","print('Correct entropy: ' + str(H))\n","\n","# Simplification\n","H = - np.log(q[0])\n","print('Manually simplified: ' + str(H))"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"fAHoba2V4QgO"},"outputs":[{"data":{"text/plain":["tensor(1.3863)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# Now using pytorch\n","import torch\n","import torch.nn.functional as F\n","\n","# Note: inputs must be `Tensors`\n","p_tensor = torch.Tensor(p) # Category labels\n","q_tensor = torch.Tensor(q) # Model predicted probability\n","\n","# Input: Model predicted probability -> Category labels\n","F.binary_cross_entropy(q_tensor, p_tensor)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMRoL9KQhvp4fYI9oP/TtpK","collapsed_sections":[],"name":"DUDL_math_entropy.ipynb","provenance":[{"file_id":"1oDaogKfz9gQYSAyQT-uF9xRI3EdrtokO","timestamp":1618209287295}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
