{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"YeuAheYyhdZw"},"outputs":[],"source":["# import libraries\n","import numpy as np\n","import torch\n","from torch.utils.data import DataLoader, TensorDataset"]},{"cell_type":"markdown","metadata":{"id":"vFv_cmvApLb0"},"source":["# Datasets"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"aykKFgznOako"},"outputs":[],"source":["# Create some data in numpy\n","n_observations = 100\n","n_features     = 20\n","\n","data = np.random.randn(n_observations, n_features)"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Y_tZ1ymVp0Sf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Numpy data:\n","<class 'numpy.ndarray'>\n","(100, 20)\n","float64\n","\n","Tensor data:\n","<class 'torch.Tensor'>\n","torch.Size([100, 20])\n","torch.float64\n","\n"]}],"source":["# Convert to pytorch tensor\n","data_tensor = torch.tensor(data)\n","\n","# Print out some information\n","print('Numpy data:')\n","print(type(data))\n","# numpy -> .shape\n","print(data.shape)\n","# The way that the information contained inside the variable is represented\n","print(data.dtype)\n","print('')\n","\n","print('Tensor data:')\n","print(type(data_tensor))\n","# torch -> .size()\n","print(data_tensor.size())\n","print(data_tensor.dtype)\n","print('')"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"WlSTQeZ2nDDR"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.float32\n","torch.int64\n"]}],"source":["# Sometimes you need to convert data types\n","data_tensor_2 = torch.tensor(data).float()\n","print(data_tensor_2.dtype)\n","\n","# \"long\" is for ints\n","data_tensor_3 = torch.tensor(data).long()\n","print(data_tensor_3.dtype)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[-0.29269996 -0.76547053  0.38155091 ... -1.68711303 -0.96522114\n","  -1.72128114]\n"," [-0.24806663  0.05221672 -0.94100489 ... -0.19540531  0.15984295\n","  -0.20650638]\n"," [ 0.55057475 -1.78516519  0.44988201 ... -1.06474119  1.30921841\n","   0.85388237]\n"," ...\n"," [-0.74095305  0.79021878  0.13239614 ... -0.59160213 -0.17878413\n","   0.36875579]\n"," [-0.10260695  0.25591158 -0.01255142 ...  0.12455077  0.19941097\n","  -0.59145312]\n"," [-1.15987477  0.56582832 -0.17253258 ...  0.52156693  1.16167555\n","   0.14769202]]\n","\n","tensor([[-0.2927, -0.7655,  0.3816,  ..., -1.6871, -0.9652, -1.7213],\n","        [-0.2481,  0.0522, -0.9410,  ..., -0.1954,  0.1598, -0.2065],\n","        [ 0.5506, -1.7852,  0.4499,  ..., -1.0647,  1.3092,  0.8539],\n","        ...,\n","        [-0.7410,  0.7902,  0.1324,  ..., -0.5916, -0.1788,  0.3688],\n","        [-0.1026,  0.2559, -0.0126,  ...,  0.1246,  0.1994, -0.5915],\n","        [-1.1599,  0.5658, -0.1725,  ...,  0.5216,  1.1617,  0.1477]])\n","\n","tensor([[ 0,  0,  0,  ..., -1,  0, -1],\n","        [ 0,  0,  0,  ...,  0,  0,  0],\n","        [ 0, -1,  0,  ..., -1,  1,  0],\n","        ...,\n","        [ 0,  0,  0,  ...,  0,  0,  0],\n","        [ 0,  0,  0,  ...,  0,  0,  0],\n","        [-1,  0,  0,  ...,  0,  1,  0]])\n"]}],"source":["print(data)\n","print('')\n","print(data_tensor_2)\n","print('')\n","print(data_tensor_3)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"u5fGd4h8mI8a"},"outputs":[{"name":"stdout","output_type":"stream","text":["(tensor([[-0.2927, -0.7655,  0.3816,  ..., -1.6871, -0.9652, -1.7213],\n","        [-0.2481,  0.0522, -0.9410,  ..., -0.1954,  0.1598, -0.2065],\n","        [ 0.5506, -1.7852,  0.4499,  ..., -1.0647,  1.3092,  0.8539],\n","        ...,\n","        [-0.7410,  0.7902,  0.1324,  ..., -0.5916, -0.1788,  0.3688],\n","        [-0.1026,  0.2559, -0.0126,  ...,  0.1246,  0.1994, -0.5915],\n","        [-1.1599,  0.5658, -0.1725,  ...,  0.5216,  1.1617,  0.1477]],\n","       dtype=torch.float64),) \n","\n","1 \n","\n","tensor([[-0.2927, -0.7655,  0.3816,  ..., -1.6871, -0.9652, -1.7213],\n","        [-0.2481,  0.0522, -0.9410,  ..., -0.1954,  0.1598, -0.2065],\n","        [ 0.5506, -1.7852,  0.4499,  ..., -1.0647,  1.3092,  0.8539],\n","        ...,\n","        [-0.7410,  0.7902,  0.1324,  ..., -0.5916, -0.1788,  0.3688],\n","        [-0.1026,  0.2559, -0.0126,  ...,  0.1246,  0.1994, -0.5915],\n","        [-1.1599,  0.5658, -0.1725,  ...,  0.5216,  1.1617,  0.1477]],\n","       dtype=torch.float64) \n","\n"]}],"source":["# Convert tensor into PyTorch Datasets\n","\n","# dataset = TensorDataset(data) # not a tensor!\n","data_set = TensorDataset(data_tensor)\n","\n","# dataset is a two-element tuple comprising (data, labels)\n","print(data_set.tensors, '\\n')\n","print(len(data_set.tensors), '\\n')\n","print(data_set.tensors[0], '\\n')"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"wpvxvxBloej3"},"outputs":[{"name":"stdout","output_type":"stream","text":["100\n","2\n","torch.Size([100, 20])\n","torch.Size([100, 1])\n"]}],"source":["# Let's try again with labels\n","labels = torch.ceil(torch.linspace(start=0.01, end=4, steps=n_observations)) # List of numbers\n","\n","# Transform to an actual matrix (column vector)\n","labels = labels.reshape((len(labels), 1))\n","# print(labels, '\\n')\n","\n","# Now make another dataset\n","data_set = TensorDataset(data_tensor, labels)\n","print(len(data_set))              # Number of observations\n","print(len(data_set.tensors))      # (Data, Labels)\n","print(data_set.tensors[0].size()) # [Observations, Features]\n","print(data_set.tensors[1].size()) # [Observations, 1]\n","\n","# For comparison\n","# print(np.shape(np.random.randint(low=5, size=n_observations)))"]},{"cell_type":"markdown","metadata":{"id":"wJ-JsNQGpIKT"},"source":["# DataLoaders"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"5_kahYcanxBg"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([100, 20])\n","BATCH INFO: torch.Size([25, 20]) | torch.Size([25, 1])\n","\n","BATCH INFO: torch.Size([25, 20]) | torch.Size([25, 1])\n","\n","BATCH INFO: torch.Size([25, 20]) | torch.Size([25, 1])\n","\n","BATCH INFO: torch.Size([25, 20]) | torch.Size([25, 1])\n","\n","tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","         1., 1., 1., 1., 1., 1., 1.]]) \n","\n","tensor([[2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n","         2., 2., 2., 2., 2., 2., 2.]]) \n","\n","tensor([[3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n","         3., 3., 3., 3., 3., 3., 3.]]) \n","\n","tensor([[4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4.,\n","         4., 4., 4., 4., 4., 4., 4.]]) \n","\n"]}],"source":["# Create a dataloader object\n","batch_size  = 25\n","data_loader = DataLoader(dataset=data_set, batch_size=batch_size)\n","\n","print(data_loader.dataset.tensors[0].shape)\n","\n","# Sizes of each batch\n","for data, label in data_loader:\n","    print(f'BATCH INFO: {data.size()} | {label.size()}\\n')\n","\n","# Inspect the labels\n","for data, label in data_loader:\n","    print(label.T, '\\n')"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"zyeJ6mjjre6p"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[3., 1., 2., 2., 1., 3., 4., 2., 1., 2., 2., 2., 4., 4., 1., 1., 3., 3.,\n","         3., 4., 4., 2., 2., 1., 1.]]) \n","\n","tensor([[3., 4., 3., 1., 3., 4., 3., 3., 2., 2., 4., 1., 2., 2., 3., 1., 2., 1.,\n","         3., 4., 2., 3., 1., 3., 2.]]) \n","\n","tensor([[3., 2., 2., 4., 3., 2., 3., 3., 3., 3., 2., 2., 1., 1., 4., 2., 2., 1.,\n","         4., 1., 4., 4., 1., 4., 4.]]) \n","\n","tensor([[4., 4., 3., 4., 3., 4., 4., 4., 1., 3., 1., 1., 4., 1., 4., 2., 1., 3.,\n","         2., 1., 1., 4., 3., 2., 1.]]) \n","\n"]}],"source":["# try again with shuffling (shuffling happens during iterations)\n","data_loader = DataLoader(dataset=data_set, batch_size=batch_size, shuffle=True)\n","\n","# Inspect the labels\n","for data, label in data_loader:\n","    print(label.T, '\\n')"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"S236TLLury42"},"outputs":[{"data":{"text/plain":["tensor([[1., 4., 4., 3., 2., 4., 3., 3., 1., 1., 3., 4., 4., 3., 4., 4., 3., 4.,\n","         2., 1., 1., 1., 2., 1., 2.]])"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["# To get only one batch (e.g., for testing)\n","\n","dat, labs = next(iter(data_loader))\n","\n","labs.T"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMDTrf0kN4swdushiJqB9Kn","collapsed_sections":[],"name":"DUDL_data_datasetLoader.ipynb","provenance":[{"file_id":"1t1AgKE-GpPPUcjGZyTF_Ie1Q9XWA3xn-","timestamp":1618172332728},{"file_id":"1qKgZ8kVcqNgwtBzHbWq5yJH_HqI6DxWW","timestamp":1617803880910},{"file_id":"15cpyHkJ435B4MqbyGjAH1poN4nCy_DE4","timestamp":1617737766196},{"file_id":"1OLuWuaFu0hcFgkQ2hh5BqbRuqUZD7XcQ","timestamp":1617734878578},{"file_id":"1XvzVGJPTJifVh8OpZVB7ykLxyUqYwQ1j","timestamp":1617196833019},{"file_id":"1bv1_y32e3KEExFKKlPfC3rpw1JxmBr8H","timestamp":1617124341706},{"file_id":"1GMq8u7KyHB2AE7Teyls9gK1T01OduQSn","timestamp":1616697516760},{"file_id":"1Ui3kyHim-e0XLgDs2mkBxVlYg7TKYtcg","timestamp":1616615469755},{"file_id":"1YpHocGI4rApOxIBb1ZghCU5L-hFnv4CK","timestamp":1616608248670}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}
