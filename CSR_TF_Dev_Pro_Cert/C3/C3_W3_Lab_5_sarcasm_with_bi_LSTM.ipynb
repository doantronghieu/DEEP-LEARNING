{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QG0e_o4savD"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/https-deeplearning-ai/tensorflow-1-public/blob/master/C3/W3/ungraded_labs/C3_W3_Lab_5_sarcasm_with_bi_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/doantronghieu/DEEP-LEARNING/main/helper_DL.py\n",
        "!pip install colorama\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams.update({'font.size':15})\n",
        "import seaborn           as sns\n",
        "sns.set()\n",
        "import helper_DL as helper"
      ],
      "metadata": {
        "id": "4ib0HTJ5sdMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2MY4-M1zuhV"
      },
      "source": [
        "# Ungraded Lab: Training a Sarcasm Detection Model using Bidirectional LSTMs\n",
        "\n",
        "In this lab, you will revisit the [News Headlines Dataset for Sarcasm Detection](https://www.kaggle.com/rmisra/news-headlines-dataset-for-sarcasm-detection/home) dataset and use it to train a Bi-LSTM Model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-AgItE6z80t"
      },
      "source": [
        "## Download the Dataset\n",
        "\n",
        "First, you will download the JSON file and extract the contents into lists."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_Wlz9i10Dmn"
      },
      "outputs": [],
      "source": [
        "# Download the dataset\n",
        "!wget https://storage.googleapis.com/tensorflow-1-public/course3/sarcasm.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pr4R0I240GOh"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Load the JSON file\n",
        "with open('./sarcasm.json', 'r') as f:\n",
        "    datastore = json.load(f)\n",
        "\n",
        "# Initialize the lists\n",
        "sentences = []\n",
        "labels    = []\n",
        "\n",
        "# Collect sentences and labels into the lists\n",
        "for item in datastore:\n",
        "    sentences.append(item['headline'])\n",
        "    labels   .append(item['is_sarcastic'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zN9-ojV55UCR"
      },
      "source": [
        "## Split the Dataset\n",
        "\n",
        "You will then split the lists into train and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50H0ZrJf035i"
      },
      "outputs": [],
      "source": [
        "training_size = 20000\n",
        "\n",
        "# Split the sentences\n",
        "training_sentences = sentences[0:training_size]\n",
        "testing_sentences  = sentences[training_size:]\n",
        "\n",
        "# Split the labels\n",
        "training_labels = labels[0:training_size]\n",
        "testing_labels  = labels[training_size:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYVNY4tE5YbN"
      },
      "source": [
        "## Data preprocessing\n",
        "\n",
        "Next, you will generate the vocabulary and padded sequences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hodsUZib1Ce7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow.keras.preprocessing as tfkp\n",
        "\n",
        "vocab_size    = 10000 # Vocabulary size of tokenizer\n",
        "max_length    = 120   # Maximum length of the padded sequences\n",
        "trunc_type   = 'post'\n",
        "padding_type = 'post'\n",
        "oov_tok      = '<OOV>'\n",
        "\n",
        "# Initialize the Tokenizer class\n",
        "tokenizer = tfkp.text.Tokenizer(num_words = vocab_size, oov_token = oov_tok)\n",
        "\n",
        "# Generate the word index dictionary\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "# Generate and pad the training sequences\n",
        "training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "training_padded    = tfkp.sequence.pad_sequences(training_sequences,\n",
        "                                                 maxlen = max_length,\n",
        "                                                 padding = padding_type,\n",
        "                                                 truncating = trunc_type) \n",
        "\n",
        "# Generate and pad the testing sequences\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "testing_padded    = tfkp.sequence.pad_sequences(testing_sequences,\n",
        "                                                maxlen = max_length,\n",
        "                                                padding = padding_type,\n",
        "                                                truncating = trunc_type) \n",
        "\n",
        "# Convert the labels lists into numpy arrays\n",
        "training_labels = np.array(training_labels)\n",
        "testing_labels  = np.array(testing_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o23gJhj95el5"
      },
      "source": [
        "## Build and Compile the Model\n",
        "\n",
        "The architecture here is almost identical to the one you used in the previous lab with the IMDB Reviews. Try to tweak the parameters and see how it affects the training time and accuracy (both training and validation)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGwXGIXvFhXW"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as tfk\n",
        "from tensorflow import nn\n",
        "from tensorflow.keras import layers, losses, optimizers, models, Model\n",
        "\n",
        "# Hyper parameters\n",
        "EMBEDDING_DIM = 16\n",
        "LSTM_DIM      = 32\n",
        "DENSE_DIM     = 24\n",
        "\n",
        "# Buid the model\n",
        "model_lstm = models.Sequential([\n",
        "    layers.Embedding(vocab_size, EMBEDDING_DIM, input_length = max_length),\n",
        "    layers.Bidirectional(layers.LSTM(LSTM_DIM)),  \n",
        "    layers.Dense(DENSE_DIM, activation = nn.relu),\n",
        "    layers.Dense(1, activation = nn.sigmoid)                         \n",
        "])\n",
        "\n",
        "model_lstm.summary()\n",
        "\n",
        "# Set the training parameters\n",
        "model_lstm.compile(loss = losses.binary_crossentropy,\n",
        "                   optimizer = optimizers.Adam(),\n",
        "                   metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krcQGm7B5g9A"
      },
      "source": [
        "## Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEKV8EMj11BW"
      },
      "outputs": [],
      "source": [
        "NUM_EPOCHS = 10\n",
        "\n",
        "# Train the model\n",
        "history_lstm = model_lstm.fit(training_padded, \n",
        "                              training_labels, \n",
        "                              epochs=NUM_EPOCHS, \n",
        "                              validation_data=(testing_padded, testing_labels))\n",
        "\n",
        "helper.plot_history_curves(history_lstm)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "C3_W3_Lab_5_sarcasm_with_bi_LSTM.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}